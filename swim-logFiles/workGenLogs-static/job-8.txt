17/01/14 01:15:17 INFO client.RMProxy: Connecting to ResourceManager at controller/10.0.0.3:8032
Max number of map tasks 40
Max number of red tasks 8
shuffleInputRatio  = 6.606579E-4
outputShuffleRatio = 0.21064146
Running on 4 nodes with 36 maps and 1 reduces.
0.3555936537665352
0.9522051541659411
Job started: Sat Jan 14 01:15:18 UTC 2017
17/01/14 01:15:18 INFO client.RMProxy: Connecting to ResourceManager at controller/10.0.0.3:8032
17/01/14 01:15:18 INFO client.RMProxy: Connecting to ResourceManager at controller/10.0.0.3:8032
17/01/14 01:15:18 INFO mapred.FileInputFormat: Total input paths to process : 1
17/01/14 01:15:18 INFO mapreduce.JobSubmitter: number of splits:2
17/01/14 01:15:19 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1484356294283_0010
17/01/14 01:15:19 INFO impl.YarnClientImpl: Submitted application application_1484356294283_0010
17/01/14 01:15:19 INFO mapreduce.Job: The url to track the job: http://controller:8088/proxy/application_1484356294283_0010/
17/01/14 01:15:19 INFO mapreduce.Job: Running job: job_1484356294283_0010
17/01/14 01:20:57 INFO mapreduce.Job: Job job_1484356294283_0010 running in uber mode : false
17/01/14 01:20:58 INFO mapreduce.Job:  map 0% reduce 0%
17/01/14 01:22:53 INFO mapreduce.Job: Task Id : attempt_1484356294283_0010_m_000001_0, Status : FAILED
Container launch failed for container_1484356294283_0010_01_000003 : java.net.SocketTimeoutException: Call From compute-1/10.0.0.4 to compute-4:45454 failed on socket timeout exception: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.0.0.4:54618 remote=compute-4/10.0.0.7:45454]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1407)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy36.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy37.startContainers(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:151)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:375)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/10.0.0.4:54618 remote=compute-4/10.0.0.7:45454]
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:515)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1079)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:974)

17/01/14 01:25:06 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
17/01/14 01:25:51 INFO mapreduce.Job:  map 100% reduce 100%
17/01/14 01:27:02 INFO mapreduce.Job: Job job_1484356294283_0010 completed successfully
17/01/14 01:27:50 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=5044889
		FILE: Number of bytes written=10439343
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=78593790
		HDFS: Number of bytes written=14136
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Other local map tasks=2
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=149160
		Total time spent by all reduces in occupied slots (ms)=19083
		Total time spent by all map tasks (ms)=149160
		Total time spent by all reduce tasks (ms)=19083
		Total vcore-seconds taken by all map tasks=149160
		Total vcore-seconds taken by all reduce tasks=19083
		Total megabyte-seconds taken by all map tasks=152739840
		Total megabyte-seconds taken by all reduce tasks=19540992
	Map-Reduce Framework
		Map input records=671089
		Map output records=463
		Map output bytes=5042284
		Map output materialized bytes=5044895
		Input split bytes=216
		Combine input records=0
		Combine output records=0
		Reduce input groups=463
		Reduce shuffle bytes=5044895
		Reduce input records=463
		Reduce output records=120
		Spilled Records=926
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=1192
		CPU time spent (ms)=148380
		Physical memory (bytes) snapshot=896860160
		Virtual memory (bytes) snapshot=2703581184
		Total committed heap usage (bytes)=570425344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	org.apache.hadoop.examples.WorkGen$Counters
		MAP_BYTES_WRITTEN=5038580
		MAP_RECORDS_WRITTEN=463
		RED_BYTES_WRITTEN=12000
		RED_RECORDS_WRITTEN=120
	File Input Format Counters 
		Bytes Read=78593574
	File Output Format Counters 
		Bytes Written=14136
Job ended: Sat Jan 14 01:27:50 UTC 2017
The job took 752 seconds.
